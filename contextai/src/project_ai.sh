#!/bin/zsh

echo "üå∏ LLM Shell Ready ‚Äì Context-aware AI CLI"
echo "Commands:"
echo "  üì•  context    ‚Äì Ask a question (uses context_engine)"
echo "  üîÅ  reinforce  ‚Äì Score decay + ranking"
echo "  üìä  top        ‚Äì Show top logs (by project)"
echo "  üß†  project    ‚Äì Old style interaction (project_llm.sh)"
echo "  üîç  recall     ‚Äì Browse past interactions"
echo "  üìù  @recall    ‚Äì Summarize across logs"
echo "  ‚ùå  exit       ‚Äì Quit"

while true; do
  echo -n "LLM> "
  read cmd

  case "$cmd" in
    context)
      echo -n "üìÅ Project: "
      read PROJ
      echo -n "üìù Prompt: "
      read PROMPT
      python3 ~/.contextai/src/context_engine.py "$PROJ" "$PROMPT" --auto
      ;;

    reinforce)
      echo -n "üìÅ Project to reinforce: "
      read PROJ
      python3 ~/.contextai/src/score_reinforcement.py "$PROJ"
      ;;

    top)
      echo -n "üìÅ Project: "
      read PROJ
      python3 -c "
from db_handler_llm import get_project_db_path
import sqlite3
db = sqlite3.connect(get_project_db_path('$PROJ'))
for row in db.execute('SELECT prompt, effective_score FROM logs ORDER BY effective_score DESC LIMIT 5'):
    print(f'{row[1]:.2f} :: {row[0][:80]}')
"
      ;;

    project)
      ~/.contextai/src/project_llm.sh
      ;;

    recall)
      ~/.contextai/src/recall.sh
      ;;

    @recall*)
      ARGS="${cmd#@recall }"
      ~/.contextai/src/recall_with_context.sh $ARGS
      ;;

    exit|quit)
      echo "üëã Later, Caramel."
      break
      ;;

    "")
      continue
      ;;

    *)
      echo "‚ùì Unknown command: $cmd"
      ;;
  esac

  echo ""
done
